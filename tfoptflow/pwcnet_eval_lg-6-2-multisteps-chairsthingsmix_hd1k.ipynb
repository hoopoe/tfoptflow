{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PWC-Net-large model evaluation (on HD1K)\n",
    "=============================================\n",
    "\n",
    "In this notebook we:\n",
    "- Evaluate the PWC-Net-large model trained on a mix of the `FlyingChairs` and `FlyingThings3DHalfRes` datasets using the multisteps S<sub>long</sub> schedule\n",
    "- Run the evaluation on the **'final'** version of the dataset, yielding an average EPE of 3x.70 with pwcnet.ckpt-595000\n",
    "- Perform basic error analysis\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own machine setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[2018a]<a name=\"2018a\"></a> Sun et al. 2018. PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume. [[arXiv]](https://arxiv.org/abs/1709.02371) [[web]](http://research.nvidia.com/publication/2018-02_PWC-Net%3A-CNNs-for) [[PyTorch (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/PyTorch) [[Caffe (Official)]](https://github.com/NVlabs/PWC-Net/tree/master/Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_eval.ipynb\n",
    "\n",
    "PWC-Net model evaluation.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from dataset_base import _DEFAULT_DS_VAL_OPTIONS\n",
    "from dataset_hd1k import HD1KDataset\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_VAL_OPTIONS\n",
    "from visualize import display_img_pairs_w_flows\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: You MUST set dataset_root to the correct path on your machine!\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    _DATASET_ROOT = 'D:/datasets/'\n",
    "else:\n",
    "    _DATASET_ROOT = '/opt/dataset/'\n",
    "_HD1K_ROOT = _DATASET_ROOT + 'hd1k_full_package'\n",
    "    \n",
    "# TODO: Set device on which to perform the evaluation\n",
    "gpu_devices = ['/device:GPU:0'] # We're doing the evaluation on a single GPU\n",
    "controller = '/device:GPU:0'\n",
    "\n",
    "# More options...\n",
    "mode = 'val_notrain'            # We're doing evaluation using the entire dataset for evaluation\n",
    "num_samples = 10                # Number of samples for error analysis\n",
    "ckpt_path = './models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000' # Model to eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset in evaluation mode, starting with the default evaluation options\n",
    "ds_opts = deepcopy(_DEFAULT_DS_VAL_OPTIONS)\n",
    "ds_opts['type'] = 'occ'\n",
    "ds_opts['val_split'] = 0\n",
    "ds = HD1KDataset(mode=mode, ds_root=_HD1K_ROOT, options=ds_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration:\n",
      "  verbose              False\n",
      "  in_memory            False\n",
      "  crop_preproc         None\n",
      "  scale_preproc        None\n",
      "  type                 occ\n",
      "  random_seed          1969\n",
      "  val_split            0\n",
      "  aug_type             None\n",
      "  mode                 val_notrain\n"
     ]
    }
   ],
   "source": [
    "# Display dataset configuration\n",
    "ds.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for evaluation, starting with the default evaluation options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_VAL_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = ckpt_path\n",
    "nn_opts['batch_size'] = 1               # Setting this to 1 leads to more accurate evaluations of the processing time \n",
    "nn_opts['use_tf_data'] = False          # Don't use tf.data reader for this simple task\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller      # Evaluate on CPU or GPU?\n",
    "\n",
    "# We're evaluating the PWC-Net-large model in quarter-resolution mode\n",
    "# That is, with a 6 level pyramid, and uspampling of level 2 by 4 in each dimension as the final flow prediction\n",
    "nn_opts['use_dense_cx'] = True\n",
    "nn_opts['use_res_cx'] = True\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# The size of the images in this dataset are not multiples of 64, while the model generates flows padded to multiples\n",
    "# of 64. Hence, we need to crop the predicted flows to their original size\n",
    "nn_opts['adapt_info'] = (1, 1088, 2560, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "... model built.\n",
      "Loading model checkpoint ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000\n",
      "... model loaded\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_path              ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, None, None, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [None, None, 2]\n",
      "  adapt_info             (1, 1088, 2560, 2)\n",
      "  sparse_gt_flow         False\n",
      "  gpu_devices            ['/device:GPU:0']\n",
      "  controller             /device:GPU:0\n",
      "  batch_size             1\n",
      "  use_tf_data            False\n",
      "  use_mixed_precision    False\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           True\n",
      "  use_res_cx             True\n",
      "  mode                   val_notrain\n",
      "  trainable params       14079050\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model in evaluation mode and display the model configuration\n",
    "nn = ModelPWCNet(mode=mode, options=nn_opts, dataset=ds)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring EPE and saving preds: 100%|###########################| 1047/1047 [21:46<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the dataset\n",
    "# Save the predictions to disk for error analysis\n",
    "# Also, get a panda dataframe with info about each sample for further error analysis\n",
    "avg_metric, avg_duration, df = nn.eval(metric_name='EPE', save_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average EPE=5.42, mean inference time=284.12ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Average EPE={avg_metric:.2f}, mean inference time={avg_duration*1000.:.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a correlation between average flow magnitude and EPE?\n",
    "sns.lmplot(x='Avg_Flow_Mag', y='EPE', data=df, fit_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the 10 worst performers by EPE?\n",
    "df = df.sort_values(by='EPE')\n",
    "df_worst = df.tail(num_samples).iloc[::-1]\n",
    "df_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_avg_flow_mag = df['Avg_Flow_Mag'].mean()\n",
    "mean_avg_flow_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the 10 best performers with an average flow magnitude?\n",
    "mean_avg_flow_mag = df['Avg_Flow_Mag'].mean()\n",
    "df_best = df[df['Avg_Flow_Mag'] >= mean_avg_flow_mag].sort_values(by='EPE').head(int(num_samples))\n",
    "df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How do the 10 worst performers look like?\n",
    "images, labels, pred_labels, ids = ds.get_samples_by_flow_ID(list(df_worst['ID']), split='val_with_preds')\n",
    "info_text = [f\"(EPE={stat[0]:.2f}, avg flow mag={stat[1]:.2f})\" for stat in zip(df_worst['EPE'], df_worst['Avg_Flow_Mag'])]\n",
    "display_img_pairs_w_flows(images, pred_labels, labels, ids, info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How do the 10 best performers (with average flow mag) look like?\n",
    "images, labels, pred_labels, ids = ds.get_samples_by_flow_ID(list(df_best['ID']), split='val_with_preds')\n",
    "info_text = [f\"(EPE={stat[0]:.2f}, avg flow mag={stat[1]:.2f})\" for stat in zip(df_best['EPE'], df_best['Avg_Flow_Mag'])]\n",
    "display_img_pairs_w_flows(images, pred_labels, labels, ids, info_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
